{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013535,
     "end_time": "2021-05-04T07:26:51.319456",
     "exception": false,
     "start_time": "2021-05-04T07:26:51.305921",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 7.194365,
     "end_time": "2021-05-04T07:26:58.526789",
     "exception": false,
     "start_time": "2021-05-04T07:26:51.332424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 引入基本資料處理用函式庫\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "# 引入 Pytorch 函式庫, 神經網路函式庫, Optimizer優化器 Loss function是要幫助我們判斷誤差值的，而Optimizer是要調整參數，來使Loss越小越好。\n",
    "import torch \n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 資料集分割器, 供多重驗證模型使用\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# 引入單字,單詞分割器\n",
    "import tokenizers\n",
    "# 引入主要模型, RoBERTa (Robustly optimized BERT approach)\n",
    "from transformers import RobertaModel, RobertaConfig\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011436,
     "end_time": "2021-05-04T07:26:58.550382",
     "exception": false,
     "start_time": "2021-05-04T07:26:58.538946",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "papermill": {
     "duration": 0.611649,
     "end_time": "2021-05-04T07:26:59.173658",
     "exception": false,
     "start_time": "2021-05-04T07:26:58.562009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "此區塊主要用於調整所有用到的函式庫使用同一個種子碼，\n",
    "確保程式及訓練過程及結果可以重現。確保亂數的值固定\n",
    "'''\n",
    "def seed_everything(seed_value):\n",
    "    #調整 random, numpy, pytorch, python本體 的種子碼\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "    \n",
    "    # 若有 GPU 版本 Pytorch 可使用\n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# 設定種子碼為 42\n",
    "seed = 42\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020382,
     "end_time": "2021-05-04T07:26:59.218691",
     "exception": false,
     "start_time": "2021-05-04T07:26:59.198309",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018546,
     "end_time": "2021-05-04T07:26:59.261783",
     "exception": false,
     "start_time": "2021-05-04T07:26:59.243237",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "關於 `tokenizers.ByteLevelBPETokenizer` 可以參考 [網址](https://github.com/huggingface/tokenizers/blob/master/bindings/python/py_src/tokenizers/implementations/byte_level_bpe.py) <br>\n",
    "關於 `encoding.offsets` 可以參考 [網址](https://huggingface.co/docs/tokenizers/python/v0.10.0/api/reference.html?highlight=offsets#tokenizers.Encoding.offsets) <br>\n",
    "關於 `encoding.ids` 可以參考 [網址](https://huggingface.co/docs/tokenizers/python/v0.10.0/api/reference.html?highlight=offsets#tokenizers.Encoding.ids) <br>\n",
    "關於 `torch.utils.data.DataLoader` 可以參考 [網址](https://pytorch.org/docs/stable/data.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "papermill": {
     "duration": 0.069607,
     "end_time": "2021-05-04T07:26:59.362108",
     "exception": false,
     "start_time": "2021-05-04T07:26:59.292501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizerFast\n",
    "\n",
    "class TweetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, max_len=96):\n",
    "        self.df = df\n",
    "        self.max_len = max_len\n",
    "        self.labeled = 'selected_text' in df\n",
    "\n",
    "        # fast-токенизатор, чтобы был return_offsets_mapping\n",
    "        self.tokenizer = RobertaTokenizerFast.from_pretrained(\n",
    "            \"roberta-base\",\n",
    "            add_prefix_space=True,\n",
    "        )\n",
    "\n",
    "    # 賦予此 Class 用 index 取值的能力， e.g. TweetDataset[1]\n",
    "    def __getitem__(self, index):\n",
    "        # 建立空的 dictionary\n",
    "        data = {}\n",
    "        # iloc:用index位置來取我們要的資料\n",
    "        row = self.df.iloc[index] \n",
    "        # 使用 class 函式 get_input_data 根據 index row 取值且放入剛剛的 data dictionary\n",
    "        ids, masks, tweet, offsets = self.get_input_data(row)\n",
    "        data['ids'] = ids\n",
    "        data['masks'] = masks #，由於 padding 會替不等長的句子們補0 ， 這時候利用masks就可以標註出非 0 的區域，也就是讓模型不被 padding 補的 0 影響判斷。\n",
    "        data['tweet'] = tweet\n",
    "        data['offsets'] = offsets #是一個表示 該單詞於句子的起始位置 結束位置的元組\n",
    "        \n",
    "        # 若 labeled 不為空集合則執行\n",
    "        if self.labeled:\n",
    "            # 使用 class 函式 get_target_idx, 額外針對目標取出 start_idx, end_idx \n",
    "            start_idx, end_idx = self.get_target_idx(row, tweet, offsets)\n",
    "            data['start_idx'] = start_idx\n",
    "            data['end_idx'] = end_idx\n",
    "            \n",
    "        # 回傳 data dictionary\n",
    "        return data\n",
    "    \n",
    "    # 定義針對此 class 呼叫 python 內建函式 len 的時候的回傳值\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    # 傳入一列資料，回傳 ids, masks, tweet, offsets 四個變數\n",
    "    def get_input_data(self, row): \n",
    "        # как раньше\n",
    "        tweet = \" \" + \" \".join(row.text.lower().split())\n",
    "\n",
    "        # токенизируем сам твит БЕЗ спец-токенов, чтобы offset'ы соответствовали строке\n",
    "        encoding = self.tokenizer(\n",
    "            tweet,\n",
    "            add_special_tokens=False,\n",
    "            return_offsets_mapping=True,\n",
    "            truncation=False,   # обрежем сами ниже, чтобы учесть спец-токены\n",
    "        )\n",
    "\n",
    "        tweet_ids = encoding[\"input_ids\"]\n",
    "        tweet_offsets = encoding[\"offset_mapping\"]\n",
    "\n",
    "        # токенизируем sentiment (positive / negative / neutral)\n",
    "        sent_enc = self.tokenizer(\n",
    "            row.sentiment,\n",
    "            add_special_tokens=False\n",
    "        )\n",
    "        sentiment_ids = sent_enc[\"input_ids\"]\n",
    "\n",
    "        # ручная сборка input_ids, как в исходном коде\n",
    "        # у RoBERTa: <s>=0, </s>=2, pad=1\n",
    "        ids = [0] + sentiment_ids + [2, 2] + tweet_ids + [2]\n",
    "\n",
    "        # offsets: на всё до твита ставим заглушки (0,0)\n",
    "        prefix_len = 1 + len(sentiment_ids) + 2  # <s> + sentiment + </s></s>\n",
    "        offsets = [(0, 0)] * prefix_len + list(tweet_offsets) + [(0, 0)]\n",
    "\n",
    "        # если слишком длинно — обрежем\n",
    "        if len(ids) > self.max_len:\n",
    "            ids = ids[:self.max_len]\n",
    "            offsets = offsets[:self.max_len]\n",
    "\n",
    "        # паддинг, если коротко\n",
    "        pad_len = self.max_len - len(ids)\n",
    "        if pad_len > 0:\n",
    "            ids += [1] * pad_len           # pad token id = 1\n",
    "            offsets += [(0, 0)] * pad_len\n",
    "\n",
    "        ids = torch.tensor(ids)\n",
    "        masks = torch.where(ids != 1, torch.tensor(1), torch.tensor(0))\n",
    "        offsets = torch.tensor(offsets)\n",
    "\n",
    "        return ids, masks, tweet, offsets\n",
    "    \n",
    "    '''\n",
    "    此資料集的目標是指出該列 Text 能夠判斷語氣的部份, \n",
    "    放置於 train 資料集的 selected_text 欄位\n",
    "    '''\n",
    "    def get_target_idx(self, row, tweet, offsets):\n",
    "        # 同上 text 處理方法\n",
    "        selected_text = \" \" +  \" \".join(row.selected_text.lower().split())\n",
    "        \n",
    "        # 取出 selected_text 的長度\n",
    "        len_st = len(selected_text) - 1\n",
    "        # 建立 text 之 index 用 #?\n",
    "        idx0 = None\n",
    "        idx1 = None\n",
    "        \n",
    "\n",
    "        # 在 e == selected_text[1] , 也就是與 selected_text 開頭的單詞相同的句子的集合內  enumerate=利用它可以同時獲得索引和值\n",
    "        for ind in (i for i, e in enumerate(tweet) if e == selected_text[1]):\n",
    "            # 若 \" \" + tweet[ind: ind+len_st] 的組合 和 selected_text 一樣\n",
    "            if \" \" + tweet[ind: ind+len_st] == selected_text:\n",
    "                # 設定 idx0 為起始點, idx1 為終止點\n",
    "                idx0 = ind\n",
    "                idx1 = ind + len_st - 1\n",
    "                break\n",
    "        \n",
    "        # 先以 len(tweet) 個 [0] 初始化 char_targets\n",
    "        char_targets = [0] * len(tweet)\n",
    "        # 若有成功取出 idx0 及 idx1\n",
    "        if idx0 != None and idx1 != None:\n",
    "            # 將 char_targets 對應 tweet 的 selected_text 位置 (idx0 ~ idx1 的範圍) 設為 1\n",
    "            for ct in range(idx0, idx1 + 1):\n",
    "                char_targets[ct] = 1\n",
    "\n",
    "        # 藉 offset 製造 target_idx 做訓練使用\n",
    "        target_idx = []\n",
    "        for j, (offset1, offset2) in enumerate(offsets):\n",
    "            # 若有發現 char_targets 中 範圍 offset1 至 offset2 的和大於 0 (代表有值)，\n",
    "            # 則將其 index 放入 target_idx\n",
    "            if sum(char_targets[offset1: offset2]) > 0:\n",
    "                target_idx.append(j)\n",
    "\n",
    "        # 起始 idx 為 target_idx 中第一個，終止 idx 則為最後一個\n",
    "        start_idx = target_idx[0]\n",
    "        end_idx = target_idx[-1]\n",
    "        \n",
    "        return start_idx, end_idx\n",
    "\n",
    "'''\n",
    "傳入 dataframe, 分割後之 train 及 val 對應的 idx, 及預設為 8 的 batch_size\n",
    "回傳有 train 及 val DataLoader 的 dictionary\n",
    "'''\n",
    "def get_train_val_loaders(df, train_idx, val_idx, batch_size=8):\n",
    "    # 藉 train_idx 及 val_idx 將 dataframe 分割成訓練及驗證 dataframe\n",
    "    train_df = df.iloc[train_idx]\n",
    "    val_df = df.iloc[val_idx]\n",
    "\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        TweetDataset(train_df), \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True,  # 打亂排序 \n",
    "        num_workers=2, # 以兩個 子行程處理\n",
    "        drop_last=True) # 當資料集 batch 無法均分時，捨棄最後一個不完整的 batch\n",
    "\n",
    "    # 要注意不要打亂排序避免 idx 錯亂\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        TweetDataset(val_df), \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=2)\n",
    "    \n",
    "    # 用 dict 儲存兩個 Loader, 並且加上對應的 Key\n",
    "    dataloaders_dict = {\"train\": train_loader, \"val\": val_loader}\n",
    "\n",
    "    return dataloaders_dict\n",
    "\n",
    "'''\n",
    "傳入 dataframe, 及預設為 32 的 batch_size\n",
    "回傳 test 資料集使用的 Loader \n",
    "'''\n",
    "def get_test_loader(df, batch_size=8):\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        TweetDataset(df), \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, # 找出答案用, 所以不打亂順序\n",
    "        num_workers=2)  # 以兩個 子行程 處理    \n",
    "    return loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020003,
     "end_time": "2021-05-04T07:26:59.402410",
     "exception": false,
     "start_time": "2021-05-04T07:26:59.382407",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model\n",
    "Transformers 的 RoBERTa 相關可以參考  [網址](https://huggingface.co/transformers/model_doc/roberta.html) <br>\n",
    "Config 可以參考 [roberta-base/config.json](https://huggingface.co/roberta-base/resolve/main/config.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "papermill": {
     "duration": 0.060535,
     "end_time": "2021-05-04T07:26:59.483286",
     "exception": false,
     "start_time": "2021-05-04T07:26:59.422751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TweetModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TweetModel, self).__init__()\n",
    "        \n",
    "        # грузим конфиг и включаем hidden_states\n",
    "        config = RobertaConfig.from_pretrained(\"roberta-base\")\n",
    "        config.output_hidden_states = True\n",
    "\n",
    "        # сама модель\n",
    "        self.roberta = RobertaModel.from_pretrained(\"roberta-base\", config=config)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(config.hidden_size, 2)\n",
    "        nn.init.normal_(self.fc.weight, std=0.02)\n",
    "        nn.init.normal_(self.fc.bias, 0.0)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # вызываем модель с именованными аргументами\n",
    "        outputs = self.roberta(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "\n",
    "        # tuple тензоров: (embeddings, layer1, ..., layer12)\n",
    "        hidden_states = outputs.hidden_states\n",
    "\n",
    "        # берём последние 4 слоя и стакаем по новой оси: (4, batch, seq_len, hidden)\n",
    "        x = torch.stack(hidden_states[-4:], dim=0)\n",
    "        # среднее по этим 4 слоям → (batch, seq_len, hidden)\n",
    "        x = x.mean(dim=0)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)  # (batch, seq_len, 2)\n",
    "\n",
    "        start_logits, end_logits = x.split(1, dim=-1)\n",
    "        start_logits = start_logits.squeeze(-1)\n",
    "        end_logits = end_logits.squeeze(-1)\n",
    "        \n",
    "        return start_logits, end_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018476,
     "end_time": "2021-05-04T07:26:59.522526",
     "exception": false,
     "start_time": "2021-05-04T07:26:59.504050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "papermill": {
     "duration": 0.030165,
     "end_time": "2021-05-04T07:26:59.571599",
     "exception": false,
     "start_time": "2021-05-04T07:26:59.541434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "建立 Loss Function 供訓練使用，\n",
    "基底是 CrossEntropy，但在此必須同時比對開頭位置及結束位置 ，CrossEntropy是在觀測預測的機率分佈與實際機率分布的誤差範圍\n",
    "所以程式將兩個的 CrossEntopyLoss 加起來計算。\n",
    "'''\n",
    "def loss_fn(start_logits, end_logits, start_positions, end_positions):\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    start_loss = ce_loss(start_logits, start_positions)\n",
    "    end_loss = ce_loss(end_logits, end_positions)    \n",
    "    total_loss = start_loss + end_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01903,
     "end_time": "2021-05-04T07:26:59.609828",
     "exception": false,
     "start_time": "2021-05-04T07:26:59.590798",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluation Function\n",
    "Jaccard index 可參考 [網址](https://zh.wikipedia.org/wiki/雅卡尔指数)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "papermill": {
     "duration": 0.045623,
     "end_time": "2021-05-04T07:26:59.675849",
     "exception": false,
     "start_time": "2021-05-04T07:26:59.630226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 藉 start_idx, end_idx, offsets 取出 test 中的 selected_text\n",
    "def get_selected_text(text, start_idx, end_idx, offsets):\n",
    "    selected_text = \"\"\n",
    "    for ix in range(start_idx, end_idx + 1):\n",
    "        # 先取出指定範圍\n",
    "        selected_text += text[offsets[ix][0]: offsets[ix][1]]\n",
    "        # 確認是否需要加上空白做辨識\n",
    "        if (ix + 1) < len(offsets) and offsets[ix][1] < offsets[ix + 1][0]:\n",
    "            selected_text += \" \"\n",
    "    return selected_text\n",
    "\n",
    "# 建立 evaluation function - Jaccard index, 又稱Intersection over Union=一種測量在特定資料集中檢測相應物體準確度的一個標準\n",
    "def jaccard(str1, str2): \n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    # 取聯集分之交集\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "# 計算 jaccard_score\n",
    "def compute_jaccard_score(text, start_idx, end_idx, start_logits, end_logits, offsets):\n",
    "    # 取出 機率最大的位置\n",
    "    start_pred = np.argmax(start_logits)\n",
    "    end_pred = np.argmax(end_logits)\n",
    "    \n",
    "    # 此區取出預測區段文字，第一個條件判斷出有可能是整句文字的狀況\n",
    "    if start_pred > end_pred:\n",
    "        pred = text\n",
    "    else:\n",
    "        pred = get_selected_text(text, start_pred, end_pred, offsets)\n",
    "    \n",
    "    # 取出正確對應語氣的文字\n",
    "    true = get_selected_text(text, start_idx, end_idx, offsets)\n",
    "    \n",
    "    # 計算 jaccard_score\n",
    "    return jaccard(true, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022978,
     "end_time": "2021-05-04T07:26:59.721021",
     "exception": false,
     "start_time": "2021-05-04T07:26:59.698043",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig, RobertaModel\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "papermill": {
     "duration": 0.051913,
     "end_time": "2021-05-04T07:26:59.793128",
     "exception": false,
     "start_time": "2021-05-04T07:26:59.741215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "訓練模型使用， 引入 Model, 訓練及驗證 dataloader, loss function , optimizer, 訓練回數, 檔案名稱\n",
    "最後會儲存訓練後的模型。\n",
    "'''\n",
    "def train_model(model, dataloaders_dict, criterion, optimizer, num_epochs, filename):\n",
    "    # 使用 GPU\n",
    "    model.cuda()\n",
    "\n",
    "    # 根據訓練回數，每回訓練進行...\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        # 判斷當前階段\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "                \n",
    "            # 預設 loss 及 jaccard 為 0\n",
    "            epoch_loss = 0.0\n",
    "            epoch_jaccard = 0.0\n",
    "            \n",
    "            # 取出當前階段(train 或 val) 所使用的資料集，資料若是 torch tensor，在 GPU 訓練要轉成 GPU 使用的 Tesnor\n",
    "            for data in tqdm((dataloaders_dict[phase])):\n",
    "                ids = data['ids'].cuda()\n",
    "                masks = data['masks'].cuda()\n",
    "                tweet = data['tweet']\n",
    "                offsets = data['offsets'].numpy()\n",
    "                start_idx = data['start_idx'].cuda()\n",
    "                end_idx = data['end_idx'].cuda()\n",
    "                \n",
    "                # 初始化 optimizer\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    \n",
    "                    # 輸入 ids, masks 得到 model 輸出\n",
    "                    start_logits, end_logits = model(ids, masks)\n",
    "                    # 計算 loss\n",
    "                    loss = criterion(start_logits, end_logits, start_idx, end_idx)\n",
    "                    \n",
    "                    # 在訓練階段要反向傳播且讓 optimizer 進行梯度下降\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    \n",
    "                    # 計算各批訓練 loss 之總和，loss.item() 目的在於將 loss 取出成 python float 形式\n",
    "                    epoch_loss += loss.item() * len(ids)\n",
    "                    \n",
    "                    # 以下步驟目的在於將 tensor 從 gpu 拿回 cpu 並且轉成 numpy array\n",
    "                    # .cpu() 用於將 tensor 放回 cpu\n",
    "                    # .detach() 用於阻斷反向傳播\n",
    "                    # .numpy() 將 tensor 轉為 numpy array\n",
    "                    start_idx = start_idx.cpu().detach().numpy()\n",
    "                    end_idx = end_idx.cpu().detach().numpy()\n",
    "                    start_logits = torch.softmax(start_logits, dim=1).cpu().detach().numpy()\n",
    "                    end_logits = torch.softmax(end_logits, dim=1).cpu().detach().numpy()\n",
    "                    \n",
    "                    # 計算本回的總 jaccard 分數總合\n",
    "                    for i in range(len(ids)):                        \n",
    "                        jaccard_score = compute_jaccard_score(\n",
    "                            tweet[i],\n",
    "                            start_idx[i],\n",
    "                            end_idx[i],\n",
    "                            start_logits[i], \n",
    "                            end_logits[i], \n",
    "                            offsets[i])\n",
    "                        epoch_jaccard += jaccard_score\n",
    "            \n",
    "            # 平均 loss 及 jaccard\n",
    "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "            epoch_jaccard = epoch_jaccard / len(dataloaders_dict[phase].dataset)\n",
    "            \n",
    "            # 印出當前 Loss 及 jaccard\n",
    "            print('Epoch {}/{} | {:^5} | Loss: {:.4f} | Jaccard: {:.4f}'.format(\n",
    "                epoch + 1, num_epochs, phase, epoch_loss, epoch_jaccard))\n",
    "            \n",
    "    # 儲存模型\n",
    "    torch.save(model.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021281,
     "end_time": "2021-05-04T07:26:59.836149",
     "exception": false,
     "start_time": "2021-05-04T07:26:59.814868",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "papermill": {
     "duration": 0.031651,
     "end_time": "2021-05-04T07:26:59.889378",
     "exception": false,
     "start_time": "2021-05-04T07:26:59.857727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定義訓練過程中數據將被輪3次\n",
    "num_epochs = 3\n",
    "# 每次批量訓練數量為 32\n",
    "batch_size = 128\n",
    "# 建立 KFold 多重驗證訓練器，分十種資料集分布且要打亂排序\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "papermill": {
     "duration": 10750.000025,
     "end_time": "2021-05-04T10:26:09.910226",
     "exception": false,
     "start_time": "2021-05-04T07:26:59.910201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2899c4b8d8d14e78b78952c5e5fa4569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9a6de6347a4c0db667a96f55f52984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | train | Loss: 2.6985 | Jaccard: 0.6050\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edec9deea7ff4ea7ad849b2a33cf75ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 |  val  | Loss: 1.6831 | Jaccard: 0.7094\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d883b7e6794bc9b88326275801aea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | train | Loss: 1.7435 | Jaccard: 0.7010\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1dda5ff19674f92a0a0f1f98da2b64c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 |  val  | Loss: 1.6295 | Jaccard: 0.7141\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "613125aca4be46c89359eb334e6b77d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | train | Loss: 1.5990 | Jaccard: 0.7158\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1fd2c4dc662400a8f126ddddee86402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 |  val  | Loss: 1.5922 | Jaccard: 0.7273\n",
      "Fold: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd5f2c6ae0df47e1bbebd822a217d076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c116d86b99e4d5ba1e09fe5ee465044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | train | Loss: 2.6710 | Jaccard: 0.6143\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ea5263f7f5047abbe1bcd569b7e43b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 |  val  | Loss: 1.7219 | Jaccard: 0.7066\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b051678042456d8aa941867910d2bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | train | Loss: 1.6788 | Jaccard: 0.7093\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda347147440441a8816faea428905d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 |  val  | Loss: 1.6100 | Jaccard: 0.7101\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "843023a8e7674c7d875191575d9a20df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | train | Loss: 1.5354 | Jaccard: 0.7253\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0bebd77f95424e9e0eb8c0b1e4c597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 |  val  | Loss: 1.5868 | Jaccard: 0.7097\n",
      "Fold: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "266d8ccd6cca40539c9dc203c9739b5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b50ddd17fc54ec1ab7fe6c8790fda4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | train | Loss: 2.5829 | Jaccard: 0.6255\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa56df03b7eb47bc8d755edc6dddff95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 |  val  | Loss: 1.6889 | Jaccard: 0.7179\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d68417b96024b4ca51fe382feb88956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | train | Loss: 1.6743 | Jaccard: 0.7088\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb4b13617034483a843d59b6f1fb8014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 |  val  | Loss: 1.6408 | Jaccard: 0.7140\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5700662bae44a8c8d5daa1bdf65fe96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | train | Loss: 1.5477 | Jaccard: 0.7248\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53a39edfa21148f1b8de96d80981b26a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 |  val  | Loss: 1.6738 | Jaccard: 0.7147\n",
      "Fold: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "176f4bf4618a4ecd8989d700ff70e958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f014b7731e2f4a3aa5ae3780f100e880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | train | Loss: 2.5432 | Jaccard: 0.6285\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d7e1278dd441aba14a427332ac34b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 |  val  | Loss: 1.7012 | Jaccard: 0.6994\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a72263d1d63463e816f07e3afd6bc89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | train | Loss: 1.6462 | Jaccard: 0.7109\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f4c2637b89247ada77d3c573c1e53bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 |  val  | Loss: 1.6400 | Jaccard: 0.7125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "489de0f6f4de42c0a9bac0b5be5da467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | train | Loss: 1.5186 | Jaccard: 0.7277\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293bfcd12bc74151b2cb30e767f057ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 |  val  | Loss: 1.6197 | Jaccard: 0.7107\n",
      "Fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60766d513e314add9cdab1e5724e017c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f7097aeef8647018ce0e2b05fffd1d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | train | Loss: 2.6955 | Jaccard: 0.6197\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53ea24c768e246b5a9170e5bd2b64762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 |  val  | Loss: 1.8246 | Jaccard: 0.6942\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9340746be42145559973a48f88520ff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | train | Loss: 1.7404 | Jaccard: 0.7055\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4752ae77819e43ee82047bca7e021c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 |  val  | Loss: 1.6571 | Jaccard: 0.7159\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e79a24d991ea4227846d55000adb95db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | train | Loss: 1.5928 | Jaccard: 0.7211\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "931aeec5add745fbb418f92775971d93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 |  val  | Loss: 1.6068 | Jaccard: 0.7160\n",
      "Fold: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5202bbb6d69c43ba8f1a1af028ae6f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47014440b5e94d3db15daa9b615be43e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | train | Loss: 2.6066 | Jaccard: 0.6188\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "010ed4f1026b475b876b6ead9834109b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 |  val  | Loss: 1.6648 | Jaccard: 0.7112\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f283ef128db45c0b4ff2e4e3a6dc731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | train | Loss: 1.6514 | Jaccard: 0.7118\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa00b2250bd6420f89c0cca9781e40dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 |  val  | Loss: 1.5604 | Jaccard: 0.7352\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b741602ed94dc98f08a9130fd39d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | train | Loss: 1.5260 | Jaccard: 0.7260\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8649a28e57054da6bbd372e81c041a63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 |  val  | Loss: 1.5634 | Jaccard: 0.7326\n",
      "Fold: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16f544ec9144dbbb366de82d2ebd9c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a48e34f6aa5411fa15dbc737f2937b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | train | Loss: 2.6380 | Jaccard: 0.6155\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b5365a51f6421eb645d62767a29a8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 |  val  | Loss: 1.7236 | Jaccard: 0.7038\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39ccf00a5af3440aaa1f8f19213cb236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | train | Loss: 1.6642 | Jaccard: 0.7105\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4abdd0ef3abc48048ecce5ea7523bfd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 |  val  | Loss: 1.6411 | Jaccard: 0.7101\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f39d7bd267874e8b90921fb5e39f4291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | train | Loss: 1.5411 | Jaccard: 0.7262\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782760a17ddc40e49df1733a10e418cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 |  val  | Loss: 1.6238 | Jaccard: 0.7194\n",
      "Fold: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "144e185694bc4d4096567a7c4360e6c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdb10e0415ed4985ae09e02070720140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | train | Loss: 2.5538 | Jaccard: 0.6305\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0bb5041203943e096840278b629825c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 |  val  | Loss: 1.6807 | Jaccard: 0.7043\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb363259a9724d2f9055e46dcee54b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | train | Loss: 1.6471 | Jaccard: 0.7138\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09140233241740f7b1418590d83a07d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 |  val  | Loss: 1.6138 | Jaccard: 0.7156\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31734e1fb5945da839b7d491ff04754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | train | Loss: 1.5237 | Jaccard: 0.7258\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6b05375b02344f780f9493e7b871f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 |  val  | Loss: 1.6178 | Jaccard: 0.7173\n",
      "Fold: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ba35e1c72e94f19bb10caf178fa607a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ffe60715ba4bc0a0f05ebcec88bbea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | train | Loss: 2.7689 | Jaccard: 0.6109\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbaea0dd136a4cf285e73eb8812d1710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 |  val  | Loss: 1.7362 | Jaccard: 0.7040\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf22d276556b4c0cb963bb688b7b3111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | train | Loss: 1.7400 | Jaccard: 0.7043\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a5ea6bf392e477c8d6a254bb01d5bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 |  val  | Loss: 1.6275 | Jaccard: 0.7175\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97ceb1e0f8a54aa6b84da8d9aa6f70d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | train | Loss: 1.6047 | Jaccard: 0.7193\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e6191147224acaa8db04abb13e5f41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 |  val  | Loss: 1.6482 | Jaccard: 0.7283\n",
      "Fold: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e698e4494552409a812499d0f5c389c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22de49693cab474a8268f0031f91b04a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | train | Loss: 2.6635 | Jaccard: 0.6145\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "954f5250c0254ecf957d62b490a56e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 |  val  | Loss: 1.6290 | Jaccard: 0.7146\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2aad698a43e4c28a2d72fde79362873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 | train | Loss: 1.6782 | Jaccard: 0.7081\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "007bb02b0a994b3faf71e7a46f3a3df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 |  val  | Loss: 1.5603 | Jaccard: 0.7271\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a890978235e401282d2b89a1d075f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 | train | Loss: 1.5403 | Jaccard: 0.7264\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e8748f9f794b41a4e90c145ee39fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 |  val  | Loss: 1.5444 | Jaccard: 0.7324\n",
      "CPU times: user 38min 16s, sys: 8 s, total: 38min 24s\n",
      "Wall time: 38min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 讀入訓練用 csv\n",
    "train_df = pd.read_csv('data/train_data.csv')\n",
    "# 將 text 內容轉型為 string\n",
    "train_df['text'] = train_df['text'].astype(str)\n",
    "# 將 selected_text 內容轉型為 string\n",
    "train_df['selected_text'] = train_df['selected_text'].astype(str)\n",
    "\n",
    "# 將資料集以十種分布反覆進行訓練及驗證\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df.sentiment), start=1): \n",
    "    print(f'Fold: {fold}')\n",
    "    # 每種資料集分布都會建立一個新 model\n",
    "    model = TweetModel()\n",
    "    # 使用 AdamW 為 optimizer, 學習率 3e-5, betas 分別為 0.9 及 0.999\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=3e-5, betas=(0.9, 0.999))\n",
    "    # 呼叫 loss function\n",
    "    criterion = loss_fn\n",
    "    # 根據 train_idx 及 val_idx 的不同重新建立 data loader\n",
    "    dataloaders_dict = get_train_val_loaders(train_df, train_idx, val_idx, batch_size)\n",
    "    \n",
    "    # 呼叫模型進行訓練，儲存的 Model 名字為 (f'roberta_fold{fold}.pth')\n",
    "    train_model(\n",
    "        model, \n",
    "        dataloaders_dict,\n",
    "        criterion, \n",
    "        optimizer, \n",
    "        num_epochs,\n",
    "        f'roberta_fold{fold}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032879,
     "end_time": "2021-05-04T10:26:09.976956",
     "exception": false,
     "start_time": "2021-05-04T10:26:09.944077",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-04T10:26:10.057584Z",
     "iopub.status.busy": "2021-05-04T10:26:10.056939Z",
     "iopub.status.idle": "2021-05-04T10:28:56.670984Z",
     "shell.execute_reply": "2021-05-04T10:28:56.671451Z"
    },
    "papermill": {
     "duration": 166.661406,
     "end_time": "2021-05-04T10:28:56.671588",
     "exception": false,
     "start_time": "2021-05-04T10:26:10.010182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 39s, sys: 6.19 s, total: 2min 45s\n",
      "Wall time: 2min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 讀入測試(輸出答案)用 csv\n",
    "test_df = pd.read_csv('../input/tweet-sentiment-extraction/test.csv')\n",
    "# 將 text 內容轉型為 string\n",
    "test_df['text'] = test_df['text'].astype(str)\n",
    "# 取得 test 用 dataloader\n",
    "test_loader = get_test_loader(test_df)\n",
    "\n",
    "# 初始化\n",
    "predictions = []\n",
    "models = []\n",
    "\n",
    "# 讀出每個 fold 訓練出的 Model 並且放到 models 中\n",
    "for fold in range(skf.n_splits):\n",
    "    model = TweetModel()\n",
    "    model.cuda()\n",
    "    model.load_state_dict(torch.load(f'roberta_fold{fold+1}.pth'))\n",
    "    model.eval()\n",
    "    models.append(model)\n",
    "\n",
    "for data in test_loader:\n",
    "    #資料若是 torch tensor，在 CPU 用要轉成 GPU 使用的 Tesnor\n",
    "    ids = data['ids'].cuda()\n",
    "    masks = data['masks'].cuda()\n",
    "    tweet = data['tweet']\n",
    "    offsets = data['offsets'].numpy()\n",
    "\n",
    "    start_logits = []\n",
    "    end_logits = []\n",
    "    # 運算出每個 fold 訓練下的輸出結果，並且放回 cpu，阻斷反向傳播，再轉成 numpy array\n",
    "    for model in models:\n",
    "        with torch.no_grad():\n",
    "            output = model(ids, masks)\n",
    "            start_logits.append(torch.softmax(output[0], dim=1).cpu().detach().numpy())\n",
    "            end_logits.append(torch.softmax(output[1], dim=1).cpu().detach().numpy())\n",
    "    # 沿著維度 0 號取平均\n",
    "    start_logits = np.mean(start_logits, axis=0)\n",
    "    end_logits = np.mean(end_logits, axis=0)\n",
    "    for i in range(len(ids)):    \n",
    "        start_pred = np.argmax(start_logits[i])\n",
    "        end_pred = np.argmax(end_logits[i])\n",
    "        # 取出預測區段文字，有可能是整句\n",
    "        if start_pred > end_pred:\n",
    "            pred = tweet[i]\n",
    "        else:\n",
    "            pred = get_selected_text(tweet[i], start_pred, end_pred, offsets[i])\n",
    "        # 放入 predictions\n",
    "        predictions.append(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032236,
     "end_time": "2021-05-04T10:28:56.736413",
     "exception": false,
     "start_time": "2021-05-04T10:28:56.704177",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-04T10:28:56.814006Z",
     "iopub.status.busy": "2021-05-04T10:28:56.813490Z",
     "iopub.status.idle": "2021-05-04T10:28:56.963599Z",
     "shell.execute_reply": "2021-05-04T10:28:56.963997Z"
    },
    "papermill": {
     "duration": 0.195424,
     "end_time": "2021-05-04T10:28:56.964118",
     "exception": false,
     "start_time": "2021-05-04T10:28:56.768694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>selected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>last session of the day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>exciting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>such a shame!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>i like it!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID             selected_text\n",
       "0  f87dea47db   last session of the day\n",
       "1  96d74cb729                  exciting\n",
       "2  eee518ae67             such a shame!\n",
       "3  01082688c6               happy bday!\n",
       "4  33987a8ee5               i like it!!"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 讀入 submission 參考格式\n",
    "sub_df = pd.read_csv('../input/tweet-sentiment-extraction/sample_submission.csv')\n",
    "# 在答案區塊放入預測值\n",
    "sub_df['selected_text'] = predictions\n",
    "# 將語氣輔助詞縮短\n",
    "sub_df['selected_text'] = sub_df['selected_text'].apply(lambda x: x.replace('!!!!', '!') if len(x.split())==1 else x)\n",
    "sub_df['selected_text'] = sub_df['selected_text'].apply(lambda x: x.replace('..', '.') if len(x.split())==1 else x)\n",
    "sub_df['selected_text'] = sub_df['selected_text'].apply(lambda x: x.replace('...', '.') if len(x.split())==1 else x)\n",
    "# 將繳交答案用 dataframe 存成 csv, 不額外建立 index\n",
    "sub_df.to_csv('submission.csv', index=False)\n",
    "# 檢查用\n",
    "sub_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "duration": 10930.622482,
   "end_time": "2021-05-04T10:28:58.205159",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-04T07:26:47.582677",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
